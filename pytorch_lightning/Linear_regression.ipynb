{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *선형회귀*\n",
        "\n",
        "출처 : https://wikidocs.net/156990"
      ],
      "metadata": {
        "id": "lzfdk8DhQRPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 머신러닝, 딥러닝 문제는 선형회귀부터 시작됩니다. 파이토치로 선형회귀를 풀어 보겠습니다. 프로그래밍에서 사용되는 경사하강법, 옵티마이저, 학습률등의 설명은 생략합니다.\n",
        "\n",
        "3가지 방법으로 선형회귀 문제를 풀어 보겠습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "DWoR9cQvQbLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1-1. 가장 기초적인 방법의 선형 회귀\n",
        "\n",
        "필요한 라이브러리를 import 합니다."
      ],
      "metadata": {
        "id": "efStaSkmQdXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# 재사용을 위해 랜덤값을 초기화 합니다.\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9emJa5uQS1n",
        "outputId": "8e1b872d-c099-41e6-dfb4-1377d1cc8dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9eec674710>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형회귀는 입력(x_train)과 정답(y_train) 데이터를 학습하여 기울기와 편향(W,b) 값을 구하고, 미지의 입력(x)이 들어왔을 때 어떤 출력(y)이 나올지 예상하는 지도학습 머신러닝 입니다. 선형회귀 예제를 위한 테스트 데이터를 선언 합니다. x_train 은 입력이고 y_train은 정답 데이터 입니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "KMmoCPUoQm07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[3], [6], [9]])\n"
      ],
      "metadata": {
        "id": "e2OHDQFAQicA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치는 텐서를 선언하고 자동미분을 통해 학습하는 구조입니다. 선형회귀 기본 가설인 y = Wx + b 에서 우리가 구하고자 하는 W와 b를 텐서로 초기화 해줍니다. requires_grad=True 를 갖는 2개의 텐서(tensor) W 와 b 를 만듭니다.\n",
        "\n",
        "requires_grad=True 는 모든 연산(operation)들을 추적해야 한다고 알려주는 parameter 입니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "48oGQ0euQtlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "hypothesis = x_train * W + b"
      ],
      "metadata": {
        "id": "rCBDfcaQQrb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "손실함수는 평균제곱오차, 옵티마이저는 SGD(Stochastic Gradient Descent)를 사용합니다.\n",
        "\n",
        "손실 함수는 실제값과 예측값의 차이(loss, cost)를 수치화해주는 함수입니다. 오차가 클수록 손실 함수의 값이 크고, 오차가 작을수록 손실 함수의 값이 작아집니다. 선형회귀란 손실 함수의 값을 최소화 하는 W, b를 찾아가는것이 학습 목표이다. 일반적으로 회귀문제에서는 평균제곱오차, 분류 문제에서는 크로스 엔트로피를 사용합니다.\n",
        "\n",
        "손실함수를 줄여나가면서 학습하는 방법은 어떤 optimizer를 사용하느냐에 따라 달라집니다. 옵티마이저는 학습 데이터(Train data)셋을 이용하여 모델을 학습 할 때 데이터의 실제 결과와 모델이 예측한 결과를 기반으로 잘 줄일 수 있게 만들어주는 역할을 하는 것입니다. 딥러닝에서 모델을 학습시킨다는건 최적화(optimization) 태스크를 수행하는 것과 같습니다. 여기서 최적화란, 손실 함수(loss funciton)의 최솟값을 찾아나가는 일련의 과정을 말합니다. 최적화는 각 학습 단계에서 모델의 오류를 줄이기 위해 모델 매개변수를 조정하는 과정입니다. 최적화 알고리즘은 이 과정이 수행되는 방식(여기에서는 확률적 경사하강법(SGD; Stochastic Gradient Descent))을 정의합니다. 한 스텝마다 이동하는 크기, 즉 보폭이 학습률(learning rate)로 정의되고, 앞으로 이동할 방향은 현 지점의 기울기(gradient)를 통해 정의됩니다.\n",
        "\n",
        "’SGD’는 경사 하강법의 일종입니다. lr은 학습률(learning rate)를 의미합니다. Stochastic Gradient Desenct(SGD)는 Loss Function을 계산할 때, 전체 데이터(Batch) 대신 일부 데이터의 모음(Mini-Batch)를 사용하여 Loss Function을 계산하여 속도가 빠르게 동작하는 옵티마이저 입니다.\n"
      ],
      "metadata": {
        "id": "FIiOhi4qQ1pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1rgF73N9u3ILp_HVDh2ANn7ka0zbnx17H\" height = 300 width = 700>"
      ],
      "metadata": {
        "id": "UdUjj6ElSgSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습하려는 모델의 매개변수와 학습률(learning rate) 하이퍼파라매터를 등록하여 옵티마이저를 초기화합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "QlXep2fhQ6Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "optimizer = optim.SGD([W, b], lr=0.01)"
      ],
      "metadata": {
        "id": "YNL8Lm1nQ0BW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최적화 단계의 각 반복(iteration)을 에폭이라고 부릅니다. 하나의 에폭은 다음 두 부분으로 구성됩니다.\n",
        "\n",
        "* 학습 단계(train loop) - 학습용 데이터셋을 반복(iterate)하고 최적의 매개변수로 수렴합니다.\n",
        "* 검증/테스트 단계(validation/test loop) - 모델 성능이 개선되고 있는지를 확인하기 위해 테스트 데이터셋을 반복(iterate)합니다.\n",
        "\n",
        "epoch 를 100으로 반복 학습 합니다. 모델의 예측값과 그에 해당하는 정답(label)을 사용하여 오차(error, 손실(loss, cost) )를 계산합니다. Pytorch에서는 gradients값들을 추후에 backward를 해줄때 계속 더해주기 때문\"에 우리는 항상 backpropagation을 하기전에 gradients를 zero로 만들어주고 시작을 해야합니다. optimizer.zero_grad()를 호출하여 모델 매개변수의 변화도를 0으로 설정합니다. 기본적으로 변화도는 더해지기(add up) 때문에 중복 계산을 막기 위해 반복할 때마다 명시적으로 0으로 설정합니다. 한번의 학습이 완료되어지면(즉, Iteration이 한번 끝나면) gradients를 항상 0으로 만들어 주어야 합니다. 만약 gradients를 0으로 초기화해주지 않으면 gradient가 의도한 방향이랑 다른 방향을 가르켜 학습이 원하는 방향으로 이루어 지지 않습니다.\n",
        "\n",
        "다음 단계는 신경망을 통해 이 예측 손실(prediction loss)을 역전파합니다. 오차 텐서(error tensor)에 .backward() 를 호출하면 역전파가 시작됩니다. 역전파 계산은 .backward()를 호출하여, 자동으로 모든 기울기(gradient)를 계산할 수 있습니다. PyTorch는 각 매개변수에 대한 손실의 변화도를 자동 저장합니다.\n",
        "\n",
        "마지막으로 .step 을 호출하여 경사하강법(gradient descent)을 시작합니다. 옵티마이저는 .grad 에 저장된 변화도에 따라 각 매개변수를 조정합니다. tensor에 대한 기울기(gradient)는 .grad 속성에 누적될 것입니다.\n",
        "\n",
        "경사하강법으로 학습합니다. 비용함수는 평귭제곱오차를 사용합니다. W = 3, b = 0 에 가까워 짐을 확인 할 수 있습니다."
      ],
      "metadata": {
        "id": "CE8MHFDWS9Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 1000 # 원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    hypothesis = x_train * W + b\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), b.item(), cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5qrrnLtSsFx",
        "outputId": "8040ed1b-c65c-415c-d4ee-a68fb9421566"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  100/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  200/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  300/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  400/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  500/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  600/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  700/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  800/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch  900/1000 W: 3.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 1000/1000 W: 3.000, b: 0.000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 이제 학습된 W 와 b 값으로 새로운 입력에 대한 예측을 할 수 있습니다. 기록을 추적하는 것(메모리를 사용하는 것)을 방지하기 위해 with torch.no.grad(): 로 코드 block을 감쌀 수 있습니다. 새로운 입력 4에 대해 예측값 y를 계산해서 pred_y를 구할 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "e6fPm7zHUdeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_var =  torch.FloatTensor([[4.0]]) \n",
        "# 입력한 값 4에 대해서 예측값 y를 계산해서 pred_y에 저장\n",
        "with torch.no_grad():\n",
        "    pred_y = test_var * W + b\n",
        "    print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nVGDD8lUOB0",
        "outputId": "9d305554-6f58-4c33-8330-0ba8bf908194"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[12.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1-2. nn.Module 로 구현하는 선형회귀\n",
        "\n",
        "\n",
        "필요한 라이브러리를 import 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "liHt1OfOVDy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# 재사용을 위해 랜덤값을 초기화 합니다.\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQKY-Gb8U6k1",
        "outputId": "086ffb0b-328e-437c-bc78-2d286fe777d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9eec674710>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형회귀 예제를 위한 테스트 데이터를 선언 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "DumfDA7pVKar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[3], [6], [9]])\n"
      ],
      "metadata": {
        "id": "cRQnRkFdVGkh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module의 nn.Linear() 함수는 선형회귀를 자동으로 수행 합니다. 입력의 차원, 출력의 차원을 인수로 받습니다. 단순 선형 회귀이므로 input_dim=1, output_dim=1로 지정합니다. 하나의 입력 에 대해서 하나의 출력 을 가지므로, 입력 차원과 출력 차원 모두 1을 인수로 사용하였습니다.\n",
        "\n",
        "model에는 가중치 W와 편향 b가 저장되어져 있습니다. 이 값은 model.parameters()라는 함수를 사용하여 불러올 수 있습니다. 나머지 코드에 대한 설명은 앞절의 코드와 동일 합니다. 옵티마이저를 정의합니다. model.parameters()를 사용하여 W와 b를 전달합니다. 학습률(learning rate)은 0.01로 정합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "F9ZmvvrKVNNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "model = nn.Linear(input_dim, output_dim)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) "
      ],
      "metadata": {
        "id": "kNsK8y-_VLxU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch 를 100으로 반복 학습 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ml26tkC9VXnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs+1):\n",
        "    prediction = model(x_train)\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0: \n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCbbtHCLVTw7",
        "outputId": "080f7a35-0f1d-4052-b579-be0b47dcecbf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 33.393265\n",
            "Epoch   10/100 Cost: 3.216369\n",
            "Epoch   20/100 Cost: 0.341221\n",
            "Epoch   30/100 Cost: 0.065809\n",
            "Epoch   40/100 Cost: 0.038018\n",
            "Epoch   50/100 Cost: 0.033880\n",
            "Epoch   60/100 Cost: 0.032064\n",
            "Epoch   70/100 Cost: 0.030536\n",
            "Epoch   80/100 Cost: 0.029099\n",
            "Epoch   90/100 Cost: 0.027731\n",
            "Epoch  100/100 Cost: 0.026427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.parameters를 통해 W와 b값을 확인 할 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "PpYbk6ZHVgZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dugA3cbVVZpl",
        "outputId": "99ad4b35-1004-4a3d-aaca-016d462da940"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[2.8116]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4282], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만들어진 모델을 사용해 새로운 입력에 대해 예측할 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ckk0M49mV8c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_var =  torch.FloatTensor([[4.0]]) \n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var) # forward 연산\n",
        "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVrV4S_eV38s",
        "outputId": "a67f0e37-9dda-4fe1-b58a-a3c5165ba1e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[11.6747]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1-3. nn.Module Class로 구현하는 선형회귀\n",
        "\n",
        "필요한 라이브러리를 import 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "S09hIxejWHLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# 재사용을 위해 랜덤값을 초기화 합니다.\n",
        "torch.manual_seed(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ccheM_gV_Bg",
        "outputId": "2a0f4107-7a21-4dfc-eef1-b2949883e87c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9eec674710>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형회귀 예제를 위한 테스트 데이터를 선언 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "dXRFee-LWNEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[3], [6], [9]])\n"
      ],
      "metadata": {
        "id": "8TpjfseKWK64"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearRegressionModel Class를 선언 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "VA10OJnbWQY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n"
      ],
      "metadata": {
        "id": "X-OtYbf8WOaD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 과 optimizer 를 만들어 줍니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "VM-CWWhwWUhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionModel()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n"
      ],
      "metadata": {
        "id": "2E5yrAO8WSMM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "1v54xzLBWX-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "    prediction = model(x_train)\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward() # backward 연산\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8_KU3mrWWMD",
        "outputId": "9ea95605-688b-43b1-cd72-0771aa9dab41"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 33.393265\n",
            "Epoch  100/2000 Cost: 0.026427\n",
            "Epoch  200/2000 Cost: 0.016330\n",
            "Epoch  300/2000 Cost: 0.010091\n",
            "Epoch  400/2000 Cost: 0.006236\n",
            "Epoch  500/2000 Cost: 0.003853\n",
            "Epoch  600/2000 Cost: 0.002381\n",
            "Epoch  700/2000 Cost: 0.001471\n",
            "Epoch  800/2000 Cost: 0.000909\n",
            "Epoch  900/2000 Cost: 0.000562\n",
            "Epoch 1000/2000 Cost: 0.000347\n",
            "Epoch 1100/2000 Cost: 0.000215\n",
            "Epoch 1200/2000 Cost: 0.000133\n",
            "Epoch 1300/2000 Cost: 0.000082\n",
            "Epoch 1400/2000 Cost: 0.000051\n",
            "Epoch 1500/2000 Cost: 0.000031\n",
            "Epoch 1600/2000 Cost: 0.000019\n",
            "Epoch 1700/2000 Cost: 0.000012\n",
            "Epoch 1800/2000 Cost: 0.000007\n",
            "Epoch 1900/2000 Cost: 0.000005\n",
            "Epoch 2000/2000 Cost: 0.000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습된 파라메터로 결과를 예측해 봅니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "na8a7QJXWXgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_var =  torch.FloatTensor([[4.0]]) \n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "with torch.no_grad():\n",
        "    pred_y = model(new_var) # forward 연산\n",
        "    print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BOAv9awWegW",
        "outputId": "4deb0fe0-d5aa-45a3-e3bb-0068f3232fad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[11.9966]])\n"
          ]
        }
      ]
    }
  ]
}